{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "## Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics\n",
    "### We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now take a look at the shapes of the X and y matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's pick one entry and see what number is written. Use indexing to pick the 36000th digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  11.,  97., 106., 175., 237.,\n",
       "       229., 146.,  59.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        39., 226., 168., 143.,  78.,  28.,  60., 148., 229., 151.,  34.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 143., 149.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  21., 128., 222., 118.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 143.,  96.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        99., 175.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  29., 210.,  26.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  44., 220.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 185., 116.,   0.,   0.,   0.,   0.,   0.,   3.,\n",
       "        32., 116., 251., 195.,  20.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  65., 216.,\n",
       "        58.,   0.,   0.,  31., 118., 199., 248., 223., 207.,  60.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  93., 212.,  63., 163., 237., 152.,\n",
       "        93.,  39.,   0.,  15.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 146., 255., 255., 100.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   6., 206., 189., 195., 250.,\n",
       "        26.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 127., 198.,  15.,   0., 126., 251.,  79.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 175.,  64.,   0.,   0.,\n",
       "         0.,  99., 239., 106.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 232.,  32.,   0.,   0.,   0.,   0.,  56., 237.,  81.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 173.,  16.,   0.,\n",
       "         0.,   0.,   0.,   0.,  93., 227.,   9.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 175.,  64.,   0.,   0.,   0.,   0.,   0.,  18.,\n",
       "       210., 116.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 117., 150.,\n",
       "         3.,   0.,   0.,   0.,   0.,   0.,  91., 199.,   6.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   4., 172., 108.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 239.,  80.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        66., 192.,   6.,   0.,   0.,   0.,   0.,  63., 247.,  15.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 137., 182.,  94.,   0.,\n",
       "         9., 105., 241., 120.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   8.,  86., 170., 215., 231., 175., 129.,   6.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[3600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can use the .reshape(28,28) function and plt.imshow() function with the parameters cmap = matplotlib.cm.binary, interpolation=\"nearest\" to make a plot of the number. Be sure to import matplotlib!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x6719d35208>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[3600].reshape(28, 28), cmap = plt.cm.binary, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use indexing to see if what the plot shows matches with the outcome of the 36000th index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[3600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training, and the rest for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:6000], X[6000:], y[:6000], y[6000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5 = np.where(y == '5', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5_train, y5_test = y5[:6000], y5[6000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets train a logistic regression to predict if a number is a 5 or not (remember to use the 'just 5s' y training set!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mingiziem\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the classifier predict correctly the 36000th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y5_pred[3600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below, and call it using: never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets fit and predict on the testing set using our never 5 Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf.fit(X_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "never5_pred = never_5_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.95078125\n",
      "F1 score: 0.7327790973871734\n",
      "Recall Score: 0.7447835833764442\n",
      "Precision Score: 0.7211554516613792\n",
      "confussion matrix: [[56531  1670]\n",
      " [ 1480  4319]]\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy Score:', accuracy_score(y5_test, y5_pred))\n",
    "print ('F1 score:', f1_score(y5_test, y5_pred))\n",
    "print ('Recall Score:', recall_score(y5_test, y5_pred))\n",
    "print ('Precision Score:', precision_score(y5_test, y5_pred))\n",
    "print ('confussion matrix:',confusion_matrix(y5_test, y5_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.909390625\n",
      "F1 score: 0.0\n",
      "Recall Score: 0.0\n",
      "Precision Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mingiziem\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confussion matrix: [[58201     0]\n",
      " [ 5799     0]]\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy score:', accuracy_score(y5_test, never5_pred))\n",
    "print ('F1 score:', f1_score(y5_test, never5_pred))\n",
    "print ('Recall Score:', recall_score(y5_test, never5_pred))\n",
    "print ('Precision Score:', precision_score(y5_test, never5_pred))\n",
    "print ('confussion matrix:',confusion_matrix(y5_test, never5_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Never5Classifier should be a binary classifer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-ffb619740a08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_roc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnever_5_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my5_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py\u001b[0m in \u001b[0;36mplot_roc_curve\u001b[1;34m(estimator, X, y, sample_weight, drop_intermediate, response_method, name, ax, **kwargs)\u001b[0m\n\u001b[0;32m    169\u001b[0m         estimator.__class__.__name__))\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     prediction_method = _check_classifer_response_method(estimator,\n",
      "\u001b[1;31mValueError\u001b[0m: Never5Classifier should be a binary classifer"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve,plot_roc_curve,roc_auc_score,auc\n",
    "plot_roc_curve(never_5_clf, X_train, y5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-149847995658>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Receiver Operating Characteristic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'AUC = %0.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lower right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_auc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y5_test, never5_pred)\n",
    " \n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
